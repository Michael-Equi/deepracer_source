<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
<link rel="stylesheet" href="../..//intel_styles.css" type="text/css" />
</head>
<body>
<div id="banner">
    <div id="bannerblock">
      <img src="../..//intel_logo.png" class="intellogo">
      <h1 class="title">Overview of OpenVINO&trade; toolkit Pre-trained Models</h1>
    </div>
  </div>
<div id="contentblock">
<h1 id="road-segmentation-adas-0001">road-segmentation-adas-0001</h1>
<h2 id="use-case-and-high-level-description">Use Case and High-Level Description</h2>
<p>This is a segmentation network to classify each pixel into four classes: BG, road, curb, mark.</p>
<h2 id="example">Example</h2>
<div class="figure">
<img src="./road-segmentation-adas-0001.png" />

</div>
<h2 id="specification">Specification</h2>
<table>
<thead>
<tr class="header">
<th align="left">Metric</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Image size</td>
<td align="left">896x512</td>
</tr>
<tr class="even">
<td align="left">GFlops</td>
<td align="left">4.770</td>
</tr>
<tr class="odd">
<td align="left">MParams</td>
<td align="left">0.184</td>
</tr>
<tr class="even">
<td align="left">Source framework</td>
<td align="left">PyTorch*</td>
</tr>
</tbody>
</table>
<h2 id="accuracy">Accuracy</h2>
<p>The quality metrics calculated on 500 images from &quot;Mighty AI&quot; dataset that was converted for four class classification task are:</p>
<table>
<thead>
<tr class="header">
<th align="left">Label</th>
<th align="left">IOU</th>
<th align="left">ACC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><strong>mean</strong></td>
<td align="left"><strong>84.4%</strong></td>
<td align="left"><strong>90.1%</strong></td>
</tr>
<tr class="even">
<td align="left">BG</td>
<td align="left">98.6%</td>
<td align="left">99.4%</td>
</tr>
<tr class="odd">
<td align="left">road</td>
<td align="left">95.4%</td>
<td align="left">97.4%</td>
</tr>
<tr class="even">
<td align="left">curbs</td>
<td align="left">72.7%</td>
<td align="left">83.1%</td>
</tr>
<tr class="odd">
<td align="left">marks</td>
<td align="left">70.8%</td>
<td align="left">80.6%</td>
</tr>
</tbody>
</table>
<ul>
<li><code>IOU=TP/(TP+FN+FP)</code></li>
<li><code>ACC=TP/GT</code></li>
<li><code>TP</code> - number of true positive pixels for given class</li>
<li><code>FN</code> - number of false negative pixels for given class</li>
<li><code>FP</code> - number of false positive pixels for given class</li>
<li><code>GT</code> - number of ground truth pixels for given class</li>
</ul>
<h2 id="performance">Performance</h2>
<p>Link to <a href="https://software.intel.com/en-us/openvino-toolkit/benchmarks">performance table</a></p>
<h2 id="inputs">Inputs</h2>
<p>A blob with a BGR image in the format: [B, C=3, H=512, W=896], where:</p>
<ul>
<li>B – batch size</li>
<li>C – number of channels</li>
<li>H – image height</li>
<li>W – image width</li>
</ul>
<h2 id="outputs">Outputs</h2>
<p>The output is a blob with the shape [B, C=4, H=512, W=896]. It can be treated as a four-channel feature map, where each channel is a probability of one of the classes: BG, road, curb, mark.</p>
<h2 id="legal-information">Legal Information</h2>
<p>[*] Other names and brands may be claimed as the property of others.</p>
</div>
</body>
</html>
